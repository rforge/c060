% setwd("C:/Projekte/explained variation/peperr/CSDA/c060/pkg/vignettes")
% setwd("~/Projekte_StatsMethods/c060/pkg/vignette")
% library(cacheSweave)
% Sweave("c060_vignette.Rnw", driver = cacheSweaveDriver)
% tools::texi2dvi("c060_vignette.tex", pdf=TRUE)

\documentclass[preprint, 11pt, authoryear]{elsarticle}

\usepackage{graphicx}
%\usepackage{mathptmx}      % use Times fonts if available on your TeX system
%\usepackage[authoryear]{natbib}
\usepackage{amssymb}
\usepackage{hyperref}

% please place your own definitions here and don't use \def but
% \newcommand{}{}
\newcommand{\Scmd}[1]{\texttt{#1}} % For R/ S commands
\newcommand{\R}{R}

\journal{Computational Statistics \& Data Analysis}

\begin{document}

\begin{frontmatter}

%% Title, authors and addresses

%% use the tnoteref command within \title for footnotes;
%% use the tnotetext command for the associated footnote;
%% use the fnref command within \author or \address for footnotes;
%% use the fntext command for the associated footnote;
%% use the corref command within \author for corresponding author footnotes;
%% use the cortext command for the associated footnote;
%% use the ead command for the email address,
%% and the form \ead[url] for the home page:
%%
%% \title{Title\tnoteref{label1}}
%% \tnotetext[label1]{}
%% \author{Name\corref{cor1}\fnref{label2}}
%% \ead{email address}
%% \ead[url]{home page}
%% \fntext[label2]{}
%% \cortext[cor1]{}
%% \address{Address\fnref{label3}}
%% \fntext[label3]{}

\setkeys{Gin}{width=\textwidth}% general figure width
\SweaveOpts{prefix.string=figures/fig, eps=FALSE}
%Because eps=FALSE, all graphics are created as pdf graphics only. This implies that the resulting tex document needs to be compiled with pdflatex rather than with latex.

\title{C060 Vignette}

\author{Martin Sill, Thomas Hielscher, Natalia Becker, Manuela Zucknick}

\address{}

%% use optional labels to link authors explicitly to addresses:
%% \author[label1,label2]{<author name>}
%% \address[label1]{<address>}
%% \address[label2]{<address>}

\begin{abstract}
%% Text of abstract

\end{abstract}

\begin{keyword}
%% keywords here, in the form: keyword \sep keyword

%% MSC codes here, in the form: \MSC code \sep code
%% or \MSC[2008] code \sep code (2000 is the default)

\end{keyword}

\end{frontmatter}

\section{Introduction}
\label{intro}

Penalized regression models provide a statistically appealing method to build prediction models from high-dimensional data sources. Since the 
introduction of the LASSO for linear regression models \citep{tibshirani96}, the methodology has been extended to generalized linear regression models,
time-to-event endpoints etc. Various penalty functions besides $L_1$- and $L_2$-norm have been proposed to select features and/or estimate their effect.

With ever increasing data, the properties of the algorithm to actually fit the model have become almost as important as the statistical model itself. 
In 2010, Friedman, Hastie and Tibshirani proposed a coordinate descent algorithm \citep{FHT2010} for generalized linear regression models, which was
later on extended to penalized Cox PH regression models \citep{simon2011}. Due to its efficiency this algorithm is considered one of the state-of-the-art
approaches to estimate penalized regression models with LASSO, ridge or elastic net penalty term. 

This algorithm has also been implemented in \R{} in the \texttt{glmnet} package. The package provides functions to tune and fit regression models, 
plot the results, and make predictions. However, in practical applications, possibly lacking an independent validation data set, some additional features and routines are
desirable to perform a more detailed analysis. We have assembled some functions that enhance the existing functionality of the \texttt{glmnet} package or
allow to use it within the framework of other existing \R{} packages. These functions have been useful in our daily work here at the German Cancer Research 
Center where prognostic models are of particular interest. Therefore, we focus on penalized Cox PH regression models in this article. But most of the functions
are applicable to all types of regression models provided by the \texttt{glmnet} package.

We provide functions to perform stability selection \citep{MeinshausenBuehlmann2010} which allows to select the most influential features at a given error level, 
alternative approaches to select the optimal parameter combination for elastic net penalties (Ref?),
and wrapper functions to use resampling-based prediction error methods provided in the framework of the \R{} package \texttt{peperr} \citep{Porz2009} to assess the
predictive accuracy.

Data from published gene expression studies are often deposited in public data repositories, for example on the Gene Expression Omnibus (GEO) website by the NCBI (National Center for Biotechnology Information): \url{http://www.ncbi.nlm.nih.gov/geo}. We find the Metzeler \textit{et al.} data \citep{metzeler08} under GEO accession number GSE12417.

Here should follow a detailed description of 
\begin{enumerate}
\item the problem (what do we want to do)
\item the existing methods and R software (what exists in glmnet package and which functions are missing)
\item the data set
\end{enumerate}

<<setup, echo=F, results=hide>>=
rm(list=ls())

#################################################
### load libraries
#################################################
library(cacheSweave)
library(Biobase)
library(genefilter)
library(glmnet)
library(parallel)
library(peperr)
library(ggplot2)
library(GEOquery)
library(limma)

#########################################
# R functions required
#########################################
source("../R/peperr_glmnet.r")
source("../R/stabilityselection.R")

#################################################
### set folder for automatically created figures
### to be specified in \SweaveOpts
#################################################
dir.create("figures",showWarnings = FALSE)

#########################################
# set cache folder
# needs different driver, to run as:
# Sweave("c060_vignette.Rnw",driver=cacheSweaveDriver)
#########################################
setCacheDir("cache")
@

<<GEOdataGSE12417, echo=F, results=hide>>=
if (file.exists("Rdata/expressionSet.Rdata")) {
    load("Rdata/expressionSet.Rdata") 
} else {
    library(GEOquery)
    
    dir.create("GEOdata",showWarnings = FALSE)
    dir.create("Rdata",showWarnings = FALSE)
    
    # download processed data files from url or if available get data from locally saved copies
    geo_exprs_data  <- getGEO("GSE12417", destdir="GEOdata",AnnotGPL=T)[[1]]
    annotation(geo_exprs_data) <- "hgu133plus2"
    
    #clinical characteristics including survival data are in "characteristics_ch1" in the phenoData 
    clin.df <- as.data.frame(strsplit2(as.character(pData(geo_exprs_data)$characteristics_ch1), split=";"))
    clin.df[,1] <- strsplit2(clin.df[,1]," ")[,7]
    clin.df[,2] <- as.numeric(sub("=", "", strsplit2(clin.df[,2]," ")[,3]))
    clin.df[,3] <- as.numeric(strsplit2(clin.df[,3]," ")[,4])
    clin.df[,4] <- as.numeric(strsplit2(clin.df[,4]," ")[,4])
    colnames(clin.df) <- c("FAB", "age", "os", "os_status")
    rownames(clin.df) <- rownames(pData(geo_exprs_data))
    pData(geo_exprs_data) <- clin.df

    save(geo_exprs_data, file="Rdata/expressionSet.Rdata")  
    unlink("GEOdata", recursive=TRUE) #delete GEOdata
} 
@

<<preprocessData, echo=F, results=hide>>=
##########################################
### unspecific filtering
#   select most varying probe sets
##########################################
rowvars    <- rowVars(exprs(geo_exprs_data))
topprobes   <- which(rowvars>=sort(rowvars,decreasing=T)[10000])
eset       <- geo_exprs_data[topprobes,]     
@

\clearpage
\section{Lasso penalised Cox PH regression model} 

\begin{figure}
<<glmnet, echo=F, results=hide, fig=TRUE, height=4>>=
##########################################
#   glmnet
##########################################
set.seed(1234)
y <- cbind(time=pData(eset)$os, status=pData(eset)$os_status)
cvres <- cv.glmnet(y=y, x=t(exprs(eset)), family="cox", nfolds=10)
res <- cvres$glmnet.fit
plot(cvres)

cof <- coef(res, s=cvres$lambda.min)
names.cof <- rownames(cof)
cofn <- cof[which(cof!=0)]
names(cofn) <- names.cof[which(cof!=0)]
@
\caption{\label{fig:cvlasso}Cross-validated partial likelihood function, including upper and lower standard deviations, as a function of $\log{\lambda}$ for the AML data set.}
\end{figure}

We tune the lasso penalty parameter by 10-fold cross-validation using the cross-validated partial log-likelihood function as the loss function. The resulting penalty parameter value leads to a final lasso model with \Sexpr{length(cofn)} selected features:
<<glmnet2, echo=F, results=verbatim>>=
print(cofn)
#cofn.ix <- predict(res, type="nonzero", s=cvres$lambda.min)
@

The selected features are highlighted as red lines in the coefficient paths shown in Figure \ref{fig:coefpath}.

\begin{figure}
<<glmnet3, echo=F, results=hide, fig=TRUE>>=
bet <- res$beta[match(names(cofn), rownames(res$beta)),]
par(mar=c(4,4,2.5,1), mgp=c(2.5,1,0), mfrow=c(2,2))

plot(res, xvar="lambda", col="gray")
glmnet:::plotCoef(bet, lambda = res$lambda, df = res$df, dev = res$dev.ratio, xvar = "lambda", add=TRUE, col="red")
abline(v=log(cvres$lambda.min), lty=3)
abline(v=log(cvres$lambda.1se), lty=3)

glmnet:::plotCoef(bet, lambda = res$lambda, df = res$df, dev = res$dev.ratio, xvar = "lambda", add=FALSE, col="red")
abline(v=log(cvres$lambda.min), lty=3)
abline(v=log(cvres$lambda.1se), lty=3)

norm <- apply(abs(res$beta), 2, sum)
plot(res, xvar="norm", col="gray")
glmnet:::plotCoef(bet, xvar = "norm", add=TRUE, col="red",
                  norm = norm, lambda = res$lambda, df = res$df, dev = res$dev.ratio)
abline(v=norm[match(cvres$lambda.min, cvres$lambda)], lty=3)
abline(v=norm[match(cvres$lambda.1se, cvres$lambda)], lty=3)

plot(res, xvar="dev", col="gray")
glmnet:::plotCoef(bet, lambda = res$lambda, df = res$df, dev = res$dev.ratio, xvar = "dev", add=TRUE, col="red")
abline(v=res$dev.ratio[match(cvres$lambda.min, cvres$lambda)], lty=3)
abline(v=res$dev.ratio[match(cvres$lambda.1se, cvres$lambda)], lty=3)
@
\caption{\label{fig:coefpath}Coefficient paths for lasso penalised Cox PH regression model applied to the AML data set.}
\end{figure}

\clearpage
At this point we would like to assess the prediction performance of the lasso model. We can do this with bootstrapped prediction error curves and corresponding integrated Brier score values (see Thomas' functions adapted for peperr/pec).

Once we have seen that this model is not very satisfactory, we can attempt to improve the model in two ways. First, we can fit an elastic net model rather than lasso (and use Natalia's search algorithm for that). And second, we can assess the stability of the lasso (and elastic net) models by stability selection and identify the most stable features (using Martin's stabilityselection.R script).

\section{Resampling based prediction errors}
\label{pec}

Once the final prognostic model is selected, we need to assess its prediction accuracy for future patients, frequently also in comparison
with established clinico-pathological prognostic markers. In many applications no independent validation data set is available.
The same data set need to be used to develop and assess the prognostic model. This is even more problematic for high-dimensional data,
where the risk of overfitting is much more present. Resampling-based methods can be used to unbiasedly estimate the predictive accuracy 
of the prognostic model in this situation. This is also called internal validation or pre-validation.

The \texttt{R} package \texttt{peperr} \citep{Porz2009} provides a modular framework for survival and binary endpoints, i.e. prognostic and
classification models. Wrapper functions for new or customized prediction model algorithms can be defined and passed to the generic call function \texttt{peperr}.  
In case of prognostic models, algorithm specific wrapper functions for model fitting, tuning and prediction are required.
Wrapper functions for selected machine learning approaches are already implemented.

Prediction accuracy is per default assessed with prediction error curves based on the time-dependent Brier score \citep{graf99}. 
But it is also possible to define and use customized accuracy measures.

We defined additional wrapper functions for the \texttt{glmnet} algorithm for fitting (\texttt{fit.glmnet}) and tuning (\texttt{complexity.glmnet}) the model,
and predicting survival probabilities (\texttt{predictProb.glmnet}) based on the fitted model and the estimated baseline hazard from the training data. 

We estimate the $L_1$-penalized Cox PH regression model for overall survival starting with the 10.000 most varying probe sets using \texttt{glmnet}. 
The $.632+$ bootstrap estimator is calculated based on subsampling \citep{BS2008} using only 20 bootstrap samples for illustration.

<<peperr, echo=T, results=hide, cache=T>>=
peperr_obj <- peperr(response=Surv(eset$os, eset$os_status), x=t(exprs(eset)),
                     fit.fun=fit.glmnet,args.fit=list(standardize=F, family="cox"),
                     complexity=complexity.glmnet, args.complexity=list(standardize=F, family="cox", nfolds=10),
                     trace=F, RNG="fixed",seed=0815, 
                     indices=resample.indices(n=dim(eset)[2], sample.n = 20, method = "sub632"))
@

Individual bootstrap results can be visualized with the \texttt{plot.peperr} function from the \texttt{peperr} package showing the selected complexity parameters, 
out-of-bag prediction error curves as well as the prediction error integrated over time, and the predictive partial log-likelihood (PLL) values. In order to calculate the predictive PLL values again an algorithm specific wrapper (here \texttt{PLL.coxnet}) needs to be defined.

In addition, we provide a slightly modified version of the prediction error curves plot function from the \texttt{peperr} package which allows to display the number still at risk (\texttt{plot.peperr.curves}) as shown in figure \ref{fig:pec1}. 

\begin{figure}
<<peperrPlot, echo=T, results=hide, fig=TRUE, width=12, height=10>>=
plot.peperr.curves(peperr_obj, at.risk=T)
@
\caption{Prediction error curves}
\label{fig:pec1}
\end{figure}

The \texttt{peperr} package is designed for high-dimensional covariates data and allows for various types of parallel computations.
Here, we re-run the calculations on 3 CPUs in parallel using a socket cluster on a Windows OS.

<<peperrParallel, echo=T, results=hide, cache=T>>=
peperr_obj_parallel <- peperr(response=Surv(eset$os, eset$os_status), x=t(exprs(eset)),
                              fit.fun=fit.glmnet,args.fit=list(standardize=F, family="cox"),
                              complexity=complexity.glmnet, args.complexity=list(standardize=F, family="cox", nfolds=10),
                              trace=F, RNG="fixed",seed=0815, cpus=3, parallel=T, clustertype="SOCK", 
                              load.list=list(functions=c("basesurv")),
                              indices=resample.indices(n=dim(eset)[2], sample.n = 20, method = "sub632"))
@

<<peperrParallelPlot, echo=F, results=hide, fig=F, width=12, height=10>>=
plot.peperr.curves(peperr_obj_parallel, at.risk=T)
@

Additional arguments can be passed directly to the \texttt{glmnet} call by specifing additional arguments for the fitting or tuning procedure.
Here, we include patient's age as mandatory model variable into the prognostic model, i.e. age is not subject to penalization.

<<peperrMandatoryParallel, echo=T, results=hide, cache=T>>=
peperr_obj_parallel_mandatory  <- peperr(response=Surv(eset$os, eset$os_status), x=data.frame(eset$age,t(exprs(eset))),
                                          fit.fun=fit.glmnet,args.fit=list(standardize=F, family="cox", 
                                                                           penalty.factor=rep(0:1,times=c(1,dim(eset)[1]))),
                                          complexity=complexity.glmnet, args.complexity=list(standardize=F, nfolds=10, family="cox",
                                                                                             penalty.factor=rep(0:1,times=c(1,dim(eset)[1]))),
                                          trace=F, RNG="fixed",seed=0815, cpus=3, parallel=T, clustertype="SOCK", 
                                          load.list=list(functions=c("basesurv")),
                                          indices=resample.indices(n=dim(eset)[2], sample.n = 20, method = "sub632"))
@

<<peperrMandatoryParallelPlot, echo=F, results=hide, fig=F, width=12, height=10>>=
lines(peperr_obj$attribute,perr(peperr_obj,"632p"),lty=1,col=6)
@

For classification models, the same wrapper functions for fitting and tuning the model are called.
Model performance measures shipped with the \texttt{peperr} packages are misclassification rate and Brier score.

We  extended functionality of the Brier score (\texttt{aggregation.brier}) and misclassification rate (\texttt{aggregation.misclass}) 
calculation for the \texttt{glmnet} algorithm, and defined AUC under the ROC curve (\texttt{aggregation.auc}) as additional performance measure.
For binary responses, the \texttt{peperr} package does not quite provide the same modular flexibility 
as for time-to-event endpoints. The predicted class probability is calculated within the performance/aggregation function by calling the algorithm specific predict function.
Whenever a new algorithm is incorporated the aggregation function has to be modified and overwritten accordingly.

For illustration purpose only we use survival status as binary response variable and build the $L_1$-penalized logistic regression model with \texttt{glmnet}.
All three prediction accuracy measures are calculated. Again, computations are run in parallel.
Results of 20 bootstrap runs are displayed in plain boxplots (figure \ref{fig:pebin1}).

<<peperrBinaryParallel, echo=F, results=hide, cache=T>>=
peperr_obj_parallel_binary_brier  <- peperr(response=eset$os_status, x=t(exprs(eset)),
                                            fit.fun=fit.glmnet,args.fit=list(standardize=F, family="binomial"),
                                            complexity=complexity.glmnet, args.complexity=list(standardize=F, family="binomial", nfolds=10),
                                            trace=F, RNG="fixed",seed=0815, cpus=3, parallel=T, clustertype="SOCK", 
                                            aggregation.fun=aggregation.brier,
                                            indices=resample.indices(n=dim(eset)[2], sample.n = 20, method = "sub632"))

peperr_obj_parallel_binary_misclass  <- peperr(response=eset$os_status, x=t(exprs(eset)),
                                               fit.fun=fit.glmnet,args.fit=list(standardize=F, family="binomial"),
                                               complexity=complexity.glmnet, args.complexity=list(standardize=F, family="binomial", nfolds=10),
                                               trace=F, RNG="fixed",seed=0815, cpus=3, parallel=T, clustertype="SOCK", 
                                               aggregation.fun=aggregation.misclass,
                                               indices=resample.indices(n=dim(eset)[2], sample.n = 20, method = "sub632"))

peperr_obj_parallel_binary_auc  <- peperr(response=eset$os_status, x=t(exprs(eset)),
                                          fit.fun=fit.glmnet,args.fit=list(standardize=F, family="binomial"),
                                          complexity=complexity.glmnet, args.complexity=list(standardize=F, family="binomial", nfolds=10),
                                          trace=F, RNG="fixed",seed=0815, cpus=3, parallel=T, clustertype="SOCK", 
                                          aggregation.fun=aggregation.auc,
                                          indices=resample.indices(n=dim(eset)[2], sample.n = 20, method = "sub632"))
@

\begin{figure}
<<peperrBinaryPlot, echo=F, results=hide, fig=TRUE, width=12, height=10 >>=
bootsamples  <- data.frame(type  = rep(c("Brier Score","Misclassification Rate","AUC"),each=20),
                           error = c(unlist(peperr_obj_parallel_binary_brier$sample.error),
                                     unlist(peperr_obj_parallel_binary_misclass$sample.error),
                                     unlist(peperr_obj_parallel_binary_auc$sample.error)))

hline_data   <- data.frame(type  = rep(c("Brier Score","Misclassification Rate","AUC"),each=4),
                           error= rep(c("mean\nout-of-bag",".632plus","apparent","null model"),3),
                                     # aggregated Brier score
                           at    = c(perr(peperr_obj_parallel_binary_brier,"resample"),
                                     perr(peperr_obj_parallel_binary_brier,"632p"),
                                     perr(peperr_obj_parallel_binary_brier,"app"),
                                     perr(peperr_obj_parallel_binary_brier,"nullmodel"),
                                     # aggregated misclassification
                                     perr(peperr_obj_parallel_binary_misclass,"resample"),
                                     perr(peperr_obj_parallel_binary_misclass,"632p"),
                                     perr(peperr_obj_parallel_binary_misclass,"app"),
                                     perr(peperr_obj_parallel_binary_misclass,"nullmodel"),
                                     # aggregated AUC
                                     perr(peperr_obj_parallel_binary_auc,"resample"),
                                     perr(peperr_obj_parallel_binary_auc,"632p"),
                                     perr(peperr_obj_parallel_binary_auc,"app"),
                                     perr(peperr_obj_parallel_binary_auc,"nullmodel")))

p    <- ggplot(bootsamples, aes(type,error))
pg   <- p + geom_boxplot(outlier.colour = rgb(0,0,0,0), outlier.size=0) + geom_jitter(position=position_jitter(width=.05)) + 
        theme_bw() + scale_y_continuous("") +  scale_x_discrete("") + facet_wrap(~ type, scales="free") +
        geom_hline(aes(yintercept=at, x=type, colour=error), hline_data, show_guide=TRUE) + opts(legend.position = "bottom")
print(pg)
@
\caption{Different bootstrap performance measures for binary classification}
\label{fig:pebin1}
\end{figure}

\clearpage
\section{Elastic net penalised Cox PH regression model}

\section{Stability selection}

\begin{figure}
<<stabilitySelection, echo=F, results=hide, fig=TRUE>>=
##########################################
### try out glmnetSS.R
#   stability selection with glmnet
##########################################

set.seed(1234)
y <- cbind(time=pData(eset)$os, status=pData(eset)$os_status)
### parallel computing not enabled on Windows
cores <- 2; if (sessionInfo()$platform=="x86_64-pc-mingw32/x64 (64-bit)") cores <- 1
res <- stability.path(y=y, x=t(exprs(eset)), weakness=1, mc.cores=cores, family="cox")
par(mar=c(4,4,2,1), mgp=c(2.5,1,0))
sel <- plot.stabpath(res, fwer=0.2, pi_thr=0.5, xvar="lambda", col.all="gray")
#sel <- plot.stabpath(res, fwer=0.2, pi_thr=0.5, xvar="norm")
#sel <- plot.stabpath(res, fwer=0.2, pi_thr=0.5, xvar="dev")
@
\caption{\label{fig:stabpath}Coefficient and stability paths for lasso penalised Cox PH regression model applied to the AML data set.}
\end{figure}

Stable features (with $\hat\Pi > 0.5$ at $\lambda =$\Sexpr{round(sel$lambda, 3)}) are:
<<stabilitySelection2, echo=F, results=verbatim>>=
print(sel$stable)
@

\clearpage
\section{Summary}

\section{Session Information}
The version number of \R{} and packages loaded for generating the vignette were:
<<sessionInfo, echo=FALSE, results=tex>>=
toLatex(sessionInfo())
@

\clearpage
\bibliographystyle{model2-names}
\bibliography{c060}   % name your BibTeX data base

\end{document}